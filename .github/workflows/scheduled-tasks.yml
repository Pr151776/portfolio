name: Scheduled Tasks (retry emails + backup)

on:
  schedule:
    - cron: '*/10 * * * *'   # every 10 minutes -> retry failed emails
    - cron: '0 2 * * *'      # daily at 02:00 UTC -> backup

jobs:
  retry_failed_emails:
    name: Retry failed emails
    runs-on: ubuntu-latest
    steps:
      - name: Invoke retry function
        env:
          RETRY_FUNCTION_URL: ${{ secrets.SUPABASE_FUNCTIONS_BASE_URL }} # e.g. https://<proj>.functions.supabase.co
          RETRY_AUTH_KEY: ${{ secrets.RETRY_INVOKE_TOKEN }} # optional: custom bearer token to protect endpoint
        run: |
          echo "Calling retry endpoint..."
          resp=$(curl -s -w "%{http_code}" -o /tmp/resp.txt -X POST "${RETRY_FUNCTION_URL}/retry_failed_emails" -H "Authorization: Bearer ${RETRY_AUTH_KEY}")
          cat /tmp/resp.txt
          echo "Status: $resp"
          if [ "$resp" -ge 400 ]; then
            echo "Retry function failed with HTTP $resp"
            # Optionally: notify Slack / PagerDuty by calling webhook
          fi

  daily_backup:
    name: Daily DB backup
    runs-on: ubuntu-latest
    if: github.event_name == 'schedule'
    steps:
      - name: Install dependencies
        run: |
          sudo apt-get update && sudo apt-get install -y postgresql-client awscli

      - name: Dump Postgres & upload to S3
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }} # Postgres connection string
          S3_BUCKET: ${{ secrets.S3_BUCKET }}
          S3_REGION: ${{ secrets.S3_REGION }}
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        run: |
          TIMESTAMP=$(date -u +"%Y-%m-%dT%H-%M-%SZ")
          FILE="supabase-backup-$TIMESTAMP.sql.gz"
          echo "Creating dump..."
          pg_dump "$DATABASE_URL" --format=c | gzip > "$FILE"
          echo "Uploading to s3..."
          aws s3 cp "$FILE" "s3://${S3_BUCKET}/${FILE}" --region ${S3_REGION}
          echo "Backup uploaded: s3://${S3_BUCKET}/${FILE}"
